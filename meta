#!/bin/bash
# Script to show all possible meta-data aspects of a file

main() {
  initialize
  parse_args $@
  validate_file $this_file
  fetch_meta
}

initialize() {
  # Setup shop
  author="Qry3vavna"
  site="https://github.com/Qry3vavna"
  version="0.3.1"
  verbose=0
  follow= ;binary= ;beta=
  tools=(stat file lsattr getfacl openssl hashdeep ssdeep)
}

parse_args() {
  # Parse given arguments
  while [ "$1" != "" ]; do
    case $1 in
      -a|--all) beta=1;binary=1;follow=1;; # Turn it all on (might take a while)
      -B|--beta) beta=1;; # Enable Beta functions
      -b|--binary) binary=1;; # Get header info on binary files
      -f|--follow) follow=1;; # Follow hardlinks
      -h|--help) usage;exit;; # Hilfe mich
      -l|--list) echo -e "$0 $version\nTools used to parse:\n${tools[@]}\n";
          sed -n '/^_BEGI/,/^_END/{/_BEG/d;/_END/d;p;}' $0|awk -F: '{print $2,$3}';
          exit 0;;
      -v|--verbose) ((verbose+=1));; # Off by default
      -V|--vers*) echo "$(basename $0 2>/dev/null||echo $0) $version"; exit 0;;
      -q|--q*) quick=1;; # Quiet & quick
      *) this_file="$1";;
    esac
    shift
  done
}

validate_file() {
  # Ensure file exists etc.
  if [[ "${#@}" -gt 0 ]];then # You gave me a file
    if [[ -f $@ ]];then # A file, not a directory or socket or such
      if [[ -r $@ ]];then # It's readable
        v_echo "[+] Parsing $@"
      else
        echo -e "\n[-] File unreadable, check permissions" # ERR3
        usage; exit 3
      fi
    else
      echo -e "\n[-] File does not exist, or perhaps a directory or other type" # ERR2
      usage; exit 2
    fi
  else
    echo -e "\n[-] No file given" # ERR1
    usage; exit 1
  fi
}

fetch_meta() {
  # Gather the data by looping through each listed tool
  for tool in ${tools[*]};do
    v_echo "[*] fetch_$tool"
    eval "fetch_${tool} $this_file"
  done
}

fetch_stat() {
  # Use the stat tool to get data
  if [[ -e $(which stat) ]];then
    if [[ -z $quick ]];then # Quick not selected?
      while read -a opt;do
        local t_opt="-c ${opt[0]}"
        local t_var=$(eval "awk -F: '/"${t_opt}"/{print \$2}'" $0) # Fetch var from _DATA_ below
        eval "${t_var}=\"$(stat -c ${opt[0]} $@ 2>/dev/null)\""
        print_res "${t_var}"
      # Parse the output of stat's help to grab valid 'file' arguments and iterate
      done < <(stat --help|sed -n '/^The val/,/^Valid/{/The val/d;/Valid/d;/^$/d;p;}')
      # Optionally follow hardlinks if requested
      if [[ "$stat_hardlinks" -gt 1 ]];then # more hardlinks, find them...
        if [[ -n "$follow" ]];then # Not default, must be manually selected since it takes so long
          v_echo "[*] Searching for hardlinked files, this might take a while..."
          stat_hard_links+=( $(find / -inum $stat_inode -type f -exec realpath {} \; 2>/dev/null &  ) )
          print_res stat_hard_links
        else
          v_echo "[!] $stat_hardlinks hardlinks found. To discover, use '-f' or '-a' options."
        fi
      fi
    else
      stat $@ 2>/dev/null # Dudes want it quick, just run stat
    fi
  else
    v_echo "\n[-] No 'stat' tool found."
  fi
}

fetch_file() {
  # Use the 'file' command's magic to determine file type
  if [[ -e $(which file) ]];then
    if [[ -z $quick ]];then # Quick not selected?
      file_list=( full mime )
      file_full="$(file -b $@ 2>/dev/null)"
      file_mime="$(file -bi $@ 2>/dev/null)"
      if [[ $(echo $file_mime|grep symlink) ]];then # Try to follow the link
        file_sym="$(file -bL $@ 2>/dev/null)"
        file_deref $@ # Unwind mutliple referenced links
        file_list+=( sym ) # Add to print list
      fi
      if [[ $(echo $file_full|grep compress) ]];then # Try to decompress
        file_zip="$(file -bz $@ 2>/dev/null)"
        file_list+=( zip ) # Add to print list
      fi
      for var in ${file_list[@]};do # Iterate vars to print
        print_res file_${var}
      done
    else
      file_full="$(file -b $@ 2>/dev/null)"
      echo -e "File_Type: $file_full" # Just run file already
    fi
    if [[ "$(echo $file_full|grep ELF)" ]];then
      if [[ -n "$binary" ]];then # Request more details on bin files
        fetch_objdump $@
        fetch_readelf $@
      fi
    fi
  else
    v_echo "\n[-] No 'file' tool found."
  fi
}

file_deref() {
  # Dererence file links
  file_links+=( "$@" )
  if [[ $(file -b $@|grep symbolic) ]];then
    file_links+=( ">" ) # Found another layer deeper: iterate!
    file_deref $(file -b $@|awk '{print $NF}')
  else
    file_list+=(links) # Add links to print queue
  fi
}

fetch_objdump() {
  # Use 'objdump' to fetch binary header info
  [[ -n "$beta" ]]||return # Temporary beta check until function fleshed out
  if [[ -e $(which objdump) ]];then
    if [[ -z $quick ]];then # Quick not selected?
      objdump -f $@ 2>/dev/null # Place holder
    else
      echo -en "objdump: "
      objdump -f $@ 2>/dev/null
    fi
  else
    v_echo "\n[-] No 'objdump' tool found."
  fi
}

fetch_readelf() {
  # Use 'readelf' to fetch binary header info
  [[ -n "$beta" ]]||return # Temporary beta check until function fleshed out
  if [[ -e $(which file) ]];then
    if [[ -z $quick ]];then # Quick not selected?
      readelf -h $@ 2>/dev/null # Place holder
    else
      echo -en "readelf: "
      readelf -h $@ 2>/dev/null
    fi
  else
    v_echo "\n[-] No 'readelf' tool found."
  fi
}

fetch_lsattr() {
  # Grab extended attributes
  if [[ -e $(which lsattr) ]];then
    if [[ -z $quick ]];then # Quick not selected?
      list_print=("")
      list_set="$(lsattr $@ 2>/dev/null|awk '{print $1}')"
      for opt in $(echo $list_set|sed -e 's/\(.\)/\1\n/g');do
        case $opt in # Loop through extended options set on file
          a) list_append="[a] Only append mode"
                list_print+=("append");;
          A) list_atime="[A] No atime record"
                list_print+=("atime");;
          c) list_autocom="[c] Auto compressed on disk by kernel"
                list_print+=("autocom");;
          C) list_nocow="[C] No copy-on-write wanted"
                list_print+=("nocow");;
          d) list_nodump="[d] Not a candidate for backup with dump"
                list_print+=("nodump");;
          D) list_dirsync="[D] Directory files written synchronously aka dirsync"
                list_print+=("dirsync");;
          e) list_extents="[e] File is using extents for mapping blocks on disk (normal)"
                list_print+=("extents");;
          E) list_experror="[E] Experimental compression error"
                list_print+=("experror");;
          h) list_largefs="[h] File is storing its blocks in units of fs blocksize, size is or was >= 2TB"
                list_print+=("largefs");;
          i) list_immutable="[i] File is immutable, can not be changed"
                list_print+=("immutable");;
          I) list_hashtree="[I] Directory indexed using hashed trees."
                list_print+=("hashtree");;
          j) list_journal="[j] Data written to file goes to journal first."
                list_print+=("journal");;
          N) list_inline="[N] File has data stored inline, within inode itself."
                list_print+=("inline");;
          s) list_zeroed="[s] When file is deleted, its blocks are zeroed and written back to disk"
                list_print+=("zeroed");;
          S) list_syncchange="[S] File changes are written synchronously to disk"
                list_print+=("syncchange");;
          t) list_nofrag="[t] File has no partial block fragment at the end when merged with other files."
                list_print+=("nofrag");;
          T) list_topdog="[T] Top of directory hierarchies for Orlov block allocator."
                list_print+=("topdog");;
          u) list_undelete="[u] When file is deleted, contents are saved, allowing undeletion."
                list_print+=("undelete");;
          X) list_rawbyte="[X] Experimental patches indicate compressed raw contents can be accessed directly"
                list_print+=("rawbyte");;
          Z) list_dirty="[Z] Experimental patches indicate compressed file is dirty."
                list_print+=("dirty");;
        esac
      done
      for var in ${list_print[@]};do # Iterate vars to print
        print_res list_${var}
      done
    else
      echo -e "Ext_Attributes: $(lsattr $@ 2>/dev/null|awk '{print $1}')" # Just list attributes ok...
    fi
  else
    v_echo "\n[-] No 'lsattr' tool found."
  fi
}

fetch_getfacl() {
  # Extended File ACL options
  [[ -n "$beta" ]]||return # Temporary beta check until function fleshed out
  if [[ -e $(which getfacl) ]];then
    if [[ -z $quick ]];then # Quick not selected?
      getfacl -c -s $@ 2>/dev/null|sed '/^$/d' #placeholder
    else # -c drops header, -s skips non-augmented or regular DAC files
      getfacl -c -s $@ 2>/dev/null|sed '/^$/d' # Just get file Access Control List
    fi
  else
    v_echo "\n[-] No 'getfacl' tool found."
  fi
}

fetch_openssl() {
  # Run through the different message digest hashes in openssl
  if [[ -e $(which openssl) ]];then
    for opt in md4 md5 ripemd160 sha sha1 sha224 sha256 sha384 sha512 whirlpool;do
      if [[ -z $quick ]];then # Quick not selected?
        # Run openssl digest select, awk parse type & hash, sed delete blanks & lowercase it
        tmp_hash="$(openssl dgst -$opt $@ 2>/dev/null|awk -F'[(=]' '{print "hash_"$1"="$3}'|sed 's/ //g;s/\(.*\)/\L\1/')"
        eval "$tmp_hash" # Sets vars hash_$hashtype
        print_res hash_$opt
      else # Just run & dump, sed delete blanks, lowercase, replace = with :
        openssl dgst -$opt $@|awk -F'[(=]' '{print "hash_"$1"="$3}'|sed 's/ //g;s/\(.*\)/\L\1/;s/=/: /g'
      fi
    done
  else
    v_echo "\n[-] No openssl found"
  fi
}

fetch_hashdeep() {
  # If it's installed run given prog through ssdeep as well
  if [[ -e $(which hashdeep) ]];then
    if [[ -z $quick ]];then # Quick not selected?
      while IFS=, read hashdeep_size hashdeep_tiger hashdeep_file;do
        print_res hashdeep_size
        print_res hashdeep_tiger
      done< <(hashdeep -sc tiger $@ 2>/dev/null|tail -1)
    else # Just run it
      echo -en "hashdeep_tiger: "
      hashdeep -sc tiger $@ 2>/dev/null|tail -1
    fi
  else
    v_echo "\n[-] No hashdeep found"
  fi
}

fetch_ssdeep() {
  # If it's installed run given prog through ssdeep as well
  if [[ -e $(which ssdeep) ]];then
    if [[ -z $quick ]];then # Quick not selected?
      while IFS=: read ssdeep_blocksize ssdeep_hash1 ssdeep_hash2 ;do
        print_res ssdeep_blocksize
        print_res ssdeep_hash1
        print_res ssdeep_hash2
      done< <(ssdeep -s $@ 2>/dev/null|tail -1|cut -d, -f1)
    else # Just run it
      echo -en "ssdeep: "
      ssdeep -s $@ 2>/dev/null|tail -1
    fi
  else
    v_echo "\n[-] No ssdeep found"
  fi
}

print_res() {
  case $out in
    *) print_list $@;;
  esac
}

print_list() {
  # Prints var & data from given variables in list format
  k="$@"; v="${@}[@]"
  echo -e "$k:\t${!v}"
  if [[ "$verbose" -gt 0 ]];then
    echo -en "description:\t" # Fetch description of given var name in _DATA_ section
    sed -n '/^_BEGI/,/^_END/{/_BEG/d;/_END/d;p;}' $0|awk -F: '/'$k'/{print $3"\n"}'
  fi # List dereferece: mywiki.wooledge.org/BashFAQ#Indirection
}

v_echo (){
  # Verbose echo, does the checking for you
  if [[ "$verbose" -gt 0 ]];then
    echo -e "$@"
  fi
}

usage() {
  # Print help
  cat << EOF
$(basename $0 2>/dev/null||echo $0) $version

View all the possible meta-data on a given file
Optionally select sections and print results
$site

USAGE: $(basename $0 2>/dev/null||echo $0) [OPTIONS] file

      -a|--all		Run all test, this could take a long time
      -B|--beta		Also run beta functions which do not parse properly yet
      -b|--binary	Get header information from binary files
      -f|--follow	Follow hardlinks and find the other files (lengthy process)
      -h|--help		This cruft
      -l|--list         List tools used to parse given file
      -v|--verbose      Print more stuff
      -V|--version      Print $0 version
      -q|--quick        No parsing, just running
                        Quickly runs all the tools it can without filtering or parsing

EOF
}

<< EOD
_BEGIN_DATA_
# command : variable : description : short_name :
lsattr $@\|awk '$1~/a/{print $1}':list_append:"Only append mode"::
lsattr $@\|awk '$1~/A/{print $1}':list_atime:"No atime record"::
lsattr $@\|awk '$1~/c/{print $1}':list_autocom:"Auto compressed on disk by kernel"::
lsattr $@\|awk '$1~/C/{print $1}':list_nocow:"No copy-on-write wanted"::
lsattr $@\|awk '$1~/d/{print $1}':list_nodump:"Not a candidate for backup with dump"::
lsattr $@\|awk '$1~/D/{print $1}':list_dirsync:"Directory files written synchronously aka dirsync"::
lsattr $@\|awk '$1~/e/{print $1}':list_extents:"File is using extents for mapping blocks on disk"::
lsattr $@\|awk '$1~/E/{print $1}':list_experror:"Experimental compression error"::
lsattr $@\|awk '$1~/h/{print $1}':list_largefs:"File is storing its blocks in units of fs blocksize, size is or was >= 2TB"::
lsattr $@\|awk '$1~/i/{print $1}':list_immutable:"File is immutable, can not be changed"::
lsattr $@\|awk '$1~/I/{print $1}':list_hashtree:"Directory indexed using hashed trees."::
lsattr $@\|awk '$1~/j/{print $1}':list_journal:"Data written to file goes to journal first."::
lsattr $@\|awk '$1~/N/{print $1}':list_inline:"File has data stored inline, within inode itself."::
lsattr $@\|awk '$1~/s/{print $1}':list_zeroed:"When file is deleted, its blocks are zeroed and written back to disk"::
lsattr $@\|awk '$1~/S/{print $1}':list_syncchange:"File changes are written synchronously to disk"::
lsattr $@\|awk '$1~/t/{print $1}':list_nofrag:"File has no partial block fragment at the end when merged with other files."::
lsattr $@\|awk '$1~/T/{print $1}':list_topdog:"Top of directory hierarchies for Orlov block allocator."::
lsattr $@\|awk '$1~/u/{print $1}':list_undelete:"When file is deleted, contents are saved, allowing undeletion."::
lsattr $@\|awk '$1~/X/{print $1}':list_rawbyte:"Experimental patches indicate compressed raw contents can be accessed directly"::
lsattr $@\|awk '$1~/Z/{print $1}':list_dirty:"Experimental patches indicate compressed file is dirty."::
stat -c %a $@:stat_mode_octal:"access rights in octal (note '#' and '0' printf flags)"::
stat -c %A $@:stat_no_atime:"access rights in human readable form"::
stat -c %b $@:stat_block_num:"number of blocks allocated (see %B)"::
stat -c %B $@:stat_block_size:"the size in bytes of each block reported by %b"::
stat -c %C $@:stat_selinux:"SELinux security context string"::
stat -c %d $@:stat_dev_dec:"device number in decimal"::
stat -c %D $@:stat_dev_hex:"device number in hex"::
stat -c %f $@:stat_mode_raw:"raw mode in hex"::
stat -c %F $@:stat_file_type:"file type"::
stat -c %g $@:stat_group_id:"group ID of owner"::
stat -c %G $@:stat_group_name:"group name of owner"::
stat -c %h $@:stat_hardlinks:"number of hard links"::
stat -c %i $@:stat_inode:"inode number"::
stat -c %m $@:stat_mount_point:"mount point"::
stat -c %n $@:stat_file_name:"file name"::
stat -c %N $@:stat_sym_link:"quoted file name with dereference if symbolic link"::
stat -c %o $@:stat_iotx_size:"optimal I/O transfer size hint"::
stat -c %s $@:stat_size_bytes:"total size, in bytes"::
stat -c %t $@:stat_dev_maj:"major device type in hex, for character/block device special files"::
stat -c %T $@:stat_dev_min:"minor device type in hex, for character/block device special files"::
stat -c %u $@:stat_user_id:"user ID of owner"::
stat -c %U $@:stat_user_name:"user name of owner"::
stat -c %w $@:stat_btime_human:"time of file birth, human-readable; - if unknown"::
stat -c %W $@:stat_btime_epoch:"time of file birth, seconds since Epoch; 0 if unknown"::
stat -c %x $@:stat_atime_human:"time of last access, human-readable"::
stat -c %X $@:stat_atime_epoch:"time of last access, seconds since Epoch"::
stat -c %y $@:stat_mtime_human:"time of last data modification, human-readable"::
stat -c %Y $@:stat_mtime_epoch:"time of last data modification, seconds since Epoch"::
stat -c %z $@:stat_ctime_human:"time of last status change, human-readable"::
stat -c %Z $@:stat_ctime_epoch:"time of last status change, seconds since Epoch"::
file -b $@:file_full:"Full descriptive text of file type"::
file -bi $@:file_mime:"MIME tag for file type"::
file -bL $@:file_sym:"File name to which given file is symbolicly linked"::
file -bz $@:file_zip:"Descriptive information on compression type"::
file_deref $@:file_links:"List of symbolic links"::
openssl dgst -md4 $@:hash_md4:MD4 message digest file hash::
openssl dgst -md5 $@:hash_md5:MD5 message digest file hash::
openssl dgst -ripemd160 $@:hash_ripemd160:RACE Integrity Primitives Evaluation Message Digest file hash::
openssl dgst -sha $@:hash_sha:Secure Hash Algorithm file hash::
openssl dgst -sha1 $@:hash_sha1:Secure Hash Algorithm 160 bit file hash::
openssl dgst -sha224 $@:hash_sha224:Secure Hash Algorithm 224 bit file hash::
openssl dgst -sha256 $@:hash_sha256:Secure Hash Algorithm 256 bit file hash::
openssl dgst -sha384 $@:hash_sha384:Secure Hash Algorithm 384 bit file hash::
openssl dgst -sha512 $@:hash_sha512:Secure Hash Algorithm 512 bit file hash::
openssl dgst -whirlpool $@:hash_whirlpool:Whirlpool 512 bit file hash::
hashdeep -sc tiger $@\|tail -1\|cut -d, -f1:hashdeep_size:Hashdeep file size::
hashdeep -sc tiger $@\|tail -1\|cut -d, -f2:hashdeep_tiger:Hashdeep Tiger Hash Algorithm::
ssdeep -s $@\|tail -1\|cut -d, -f1:ssdeep_blocksize:ssdeep blocksize::
ssdeep -s $@\|tail -1\|cut -d, -f1:ssdeep_hash1:ssdeep first hash::
ssdeep -s $@\|tail -1\|cut -d, -f1:ssdeep_hash2:ssdeep second hash::
_END_DATA_
EOD

#=-+-=#
main $@
